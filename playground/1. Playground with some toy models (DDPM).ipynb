{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec049100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the default device to GPU\n",
    "    torch.cuda.set_device(0)  # You can specify the GPU index (0, 1, etc.) if you have multiple GPUs\n",
    "else:\n",
    "    print(\"No GPU available. Switching to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "complex_data = np.load('../layer_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c51283",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = torch.Tensor(complex_data)\n",
    "def transform(data):\n",
    "    min_, max_ = torch.min(data, axis=1), torch.max(data, axis=1)\n",
    "    data_transformed = 2 * (data.sub(min_.values[:, None])).div((max_.values - min_.values)[:, None]) - 1\n",
    "    return data_transformed, min_, max_\n",
    "\n",
    "data_transformed, min_, max_ = transform(complex_data[:2, :])\n",
    "data_transformed = data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Positional or Fourier for time embedding\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "    \n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "        # Randomly sample weights (frequencies) during initialization. \n",
    "        # These weights (frequencies) are fixed during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        # Cosine(2 pi freq x), Sine(2 pi freq x)\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#different scheduler\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "def quadratic_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n",
    "\n",
    "def sigmoid_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    betas = torch.linspace(-6, 6, timesteps)\n",
    "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
    "\n",
    "def sigmoid_beta_schedule1(timesteps, start = -3, end = 3, tau = 1, clamp_min = 1e-5):\n",
    "    \"\"\"\n",
    "    sigmoid schedule\n",
    "    proposed in https://arxiv.org/abs/2212.11972 - Figure 8\n",
    "    better for images > 64x64, when used during training\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    t = torch.linspace(0, timesteps, steps, dtype = torch.float64) / timesteps\n",
    "    v_start = torch.tensor(start / tau).sigmoid()\n",
    "    v_end = torch.tensor(end / tau).sigmoid()\n",
    "    alphas_cumprod = (-((t * (end - start) + start) / tau).sigmoid() + v_end) / (v_end - v_start)\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)\n",
    "\n",
    "def logsnr_schedule_cosine(t, logsnr_min=-20., logsnr_max=20.):\n",
    "    b = tf.math.atan(tf.exp(-0.5 * logsnr_max))\n",
    "    a = tf.math.atan(tf.exp(-0.5 * logsnr_min)) - b\n",
    "    return -2. * tf.math.log(tf.math.tan(a * tf.cast(t,tf.float32) + b))\n",
    "\n",
    "\n",
    "def inv_logsnr_schedule_cosine(logsnr, logsnr_min=-20., logsnr_max=20.):\n",
    "    b = tf.math.atan(tf.exp(-0.5 * logsnr_max))\n",
    "    a = tf.math.atan(tf.exp(-0.5 * logsnr_min)) - b\n",
    "    return tf.math.atan(tf.exp(-0.5 * tf.cast(logsnr,tf.float32)))/a -b/a\n",
    "\n",
    "    \n",
    "\n",
    "def get_logsnr_alpha_sigma(time):\n",
    "    logsnr = self.logsnr_schedule_cosine(time)\n",
    "    alpha = tf.sqrt(tf.math.sigmoid(logsnr))\n",
    "    sigma = tf.sqrt(tf.math.sigmoid(-logsnr))\n",
    "        \n",
    "    return logsnr, alpha, sigma\n",
    "\n",
    "\n",
    "# Simple scalar noise schedule, i.e. gamma(t) in the vdm paper:\n",
    "# gamma(t) = abs(w) * t + b\n",
    "class NoiseSchedule(nn.Module):\n",
    "\n",
    "    def setup(self):\n",
    "        init_bias = init_gamma_0\n",
    "        init_scale = init_gamma_1 - init_gamma_0\n",
    "        self.w = self.param('w', constant_init(init_scale), (1,))\n",
    "        self.b = self.param('b', constant_init(init_bias), (1,))\n",
    "\n",
    "    def __call__(self, t):\n",
    "        return abs(self.w) * t + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d241554",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = torch.Tensor(np.vstack((data_transformed[0,0:128*64],data_transformed[1,0:128*64]))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642533ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "\n",
    "#change the beta sc\n",
    "betas = cosine_beta_schedule(timesteps)\n",
    "alphas = 1 - betas\n",
    "alphas_ = torch.cumprod(alphas, axis=0)\n",
    "variance = 1 - alphas_\n",
    "sd = torch.sqrt(variance)\n",
    "\n",
    "\n",
    "def forward_process(x_start, timestep, noise=None):\n",
    "    \"\"\" Diffuse the data (t == 0 means diffused for 1 step) \"\"\"\n",
    "    x_seq = [x_start]\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    noise_at_t = torch.normal(0, std=1, size=x_start.size())\n",
    "    for n in range(timestep):\n",
    "        x_seq.append(x_start.mul(torch.sqrt(alphas_[n])) + noise_at_t.mul(sd[n]))\n",
    "    return x_seq\n",
    "\n",
    "x_seq = forward_process(dataset1, 200)\n",
    "print(len(x_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 6, figsize=(28, 3))  #cosine scheduler\n",
    "for i in range(6): \n",
    "    axs[i].scatter(x_seq[int((i / 1) * 5)][0], x_seq[int((i / 1) * 5)][1], s=10);\n",
    "    axs[i].set_axis_off(); axs[i].set_title('$q(\\mathbf{x}_{'+str(int((i / 1) * 5))+'})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(28, 3))\n",
    "for i in range(9):\n",
    "    axs[i].scatter(x_seq[int((i / 10.0) * timesteps)][0], x_seq[int((i / 10.0) * timesteps)][1], s=10);\n",
    "    axs[i].set_axis_off(); axs[i].set_title('$q(\\mathbf{x}_{'+str(int((i / 10.0) * timesteps))+'})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some reparameterization trick\n",
    "import torch.nn.functional as F\n",
    "\n",
    "alphas_prev_ = F.pad(alphas_[:-1], [1, 0], \"constant\", 1.0)\n",
    "sigma_squared_q_t = (1 - alphas) * (1 - alphas_) / (1 - alphas_prev_)\n",
    "log_sigma_squared_q_t = torch.log(1-alphas) + torch.log(1-alphas_) - torch.log(1-alphas_prev_)\n",
    "sigma_squared_q_t_corrected = torch.exp(log_sigma_squared_q_t)\n",
    "\n",
    "# how to add noise to the data\n",
    "def get_noisy(batch, timestep):\n",
    "    noise_at_t = torch.normal(0, std=1, size=batch.size())\n",
    "    added_noise_at_t = batch.mul(torch.sqrt(alphas_[timestep])) + noise_at_t.mul(sd[timestep])\n",
    "    return added_noise_at_t, noise_at_t\n",
    "\n",
    "def recover_original(batch, timestep, noise):\n",
    "    true_data = (batch.sub(noise.mul(sd[timestep]))).div(alphas_[timestep])\n",
    "    return true_data\n",
    "    \n",
    "added_noise_at_t, noise = get_noisy(data_transformed[:2, :], 20)\n",
    "plt.scatter(added_noise_at_t[0], added_noise_at_t[1])\n",
    "\n",
    "posterior_variance = (betas) * (1 - alphas_prev_) / (1 - alphas_)\n",
    "\n",
    "## https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L196\n",
    "## https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L78\n",
    "log_posterior_variance = torch.log(torch.hstack([posterior_variance[1], posterior_variance[1:]]))\n",
    "\n",
    "# not sure why we are multiplying by 1/2 here\n",
    "posterior_variance_corrected = torch.exp(log_posterior_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinusoidalPositionEmbeddings = SinusoidalPositionEmbeddings(8)\n",
    "position_embeddings = sinusoidalPositionEmbeddings(torch.arange(0, timesteps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687b8c8",
   "metadata": {},
   "source": [
    "## Denoising diffusion probabilistic models (DDPM)\n",
    "\n",
    "In a very recent article, Ho et al. [ [ 1 ] ](#ref1) constructed over the diffusion models idea, by proposing several enhancements allowing to enhance the quality of the results. First, they proposed to rely on the following parameterization for the mean function\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\theta}(\\mathbf{x}_{t}, t) = \\frac{1}{\\sqrt{\\alpha_{t}}} \\left( (\\mathbf{x}_{t} - \\frac{\\beta_{t}}{\\sqrt{1 - \\bar{\\alpha}}_{t}} \\mathbf{\\epsilon}_{\\theta} (\\mathbf{x}_{t}, t) \\right) \n",
    "$$\n",
    "\n",
    "Note that now, the model is trained at outputing directly a form of _noise_ function, which is used in the sampling process. Furthermore, the authors suggest to rather use a fixed variance function\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_{t}}} \\left( \\mathbf{x}_{t} - \\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha_{t}}}} \\mathbf{\\epsilon}_{\\theta}(\\mathbf{x}_{t}, t) \\right) + \\sigma_{t}\\mathbf{z}\n",
    "$$\n",
    "\n",
    "This leads to a new sampling procedure for the reverse process as follows (we also quickly redefine the model to output the correct dimensionality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4011162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simplemodel(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_units=128):\n",
    "        super(simplemodel, self).__init__()\n",
    "        # hidden_units = 128\n",
    "        self.position_mlp = nn.Sequential(\n",
    "          # SinusoidalPositionEmbeddings(8),\n",
    "          nn.SiLU(), \n",
    "          nn.Linear(8, 2)\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2, int(hidden_units), bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(int(hidden_units), int(hidden_units/4), bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(int(hidden_units/4), int(hidden_units/8), bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(int(hidden_units/8), int(hidden_units/4), bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(int(hidden_units/4), int(hidden_units), bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(int(hidden_units), 2, bias=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x, timestep=None):\n",
    "        if timestep is not None:\n",
    "            # using the generated embeddings for each position, instead of generating it each time\n",
    "            timestep_embeddings = position_embeddings[timestep.long()]\n",
    "            time_embeddings = self.position_mlp(timestep_embeddings)\n",
    "            # concatenating time embeddings to input\n",
    "            x = x.add(time_embeddings)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ecc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod) #sd\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6301980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batch_get_variance(self, t, prev_t):\n",
    "        alpha_prod_t = self.alphas_cumprod[t]\n",
    "        alpha_prod_t_prev = self.alphas_cumprod[ torch.clip(prev_t, min=0) ]\n",
    "        alpha_prod_t_prev[ prev_t < 0 ] = torch.tensor(1.0)\n",
    "        beta_prod_t = 1 - alpha_prod_t\n",
    "        beta_prod_t_prev = 1 - alpha_prod_t_prev\n",
    "\n",
    "        variance = (beta_prod_t_prev / beta_prod_t) * (1 - alpha_prod_t / alpha_prod_t_prev)\n",
    "\n",
    "        return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=200\n",
    "def noise_estimation_loss(model, x_0):\n",
    "    batch_size = x_0.shape[0]\n",
    "    device = x_0.device  # Get the device of x_0\n",
    "\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,), device=device)\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long()\n",
    "\n",
    "    a = extract(alphas_bar_sqrt, t, x_0)\n",
    "    am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    e = torch.randn_like(x_0, device=device)\n",
    "\n",
    "    x = x_0 * a + e * am1\n",
    "    output = model(x, t)\n",
    "    return (e - output).square().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4389d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ddim\n",
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict\n",
    "\n",
    "        \n",
    "        \n",
    "#alternative implementation for hyperparameter\n",
    "#Exponential Moving Average it's a technique used to make results better and more stable training. \n",
    "#It works by keeping a copy of the model weights of the previous iteration and updating the current iteration weights by a factor of (1-beta). \n",
    "class EMA1:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = 0\n",
    "\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "\n",
    "    def step_ema(self, ema_model, model, step_start_ema=2000):\n",
    "        if self.step < step_start_ema:\n",
    "            self.reset_parameters(ema_model, model)\n",
    "            self.step += 1\n",
    "            return\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(input, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(input, 0, t.to(input.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape)\n",
    "\n",
    "def p_sample(model, x, t):\n",
    "    t = torch.tensor([t])\n",
    "    # Factor to the model output\n",
    "    eps_factor = ((1 - extract(alphas, t, x)) / extract(one_minus_alphas_bar_sqrt, t, x))\n",
    "    # Model output\n",
    "    eps_theta = model(x, t)\n",
    "    # Final values\n",
    "    mean = (1 / extract(alphas, t, x).sqrt()) * (x - (eps_factor * eps_theta))\n",
    "    # Generate z\n",
    "    z = torch.randn_like(x)\n",
    "    # Fixed sigma\n",
    "    sigma_t = extract(betas, t, x).sqrt()\n",
    "    sample = mean + sigma_t * z\n",
    "    return (sample)\n",
    "\n",
    "def p_sample_loop(model, shape):\n",
    "    cur_x = torch.randn(shape)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps)):\n",
    "        cur_x = p_sample(model, cur_x, i)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simplemodel()\n",
    "#model = UNetWithTimestep(input_channels, output_channels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "dataset = dataset1.T\n",
    "\n",
    "# Create EMA model\n",
    "#ema = EMA(0.9)\n",
    "#ema.register(model)\n",
    "\n",
    "#loss_fn = nn.MSELoss()\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "losses = []\n",
    "for t in range(200):\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(dataset.size()[0])\n",
    "    for i in range(0, dataset.size()[0], batch_size):\n",
    "        # Retrieve current batch\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        \n",
    "        batch_x = dataset[indices]\n",
    "\n",
    "        # Compute the loss.\n",
    "        \n",
    "        loss = noise_estimation_loss(model, batch_x)\n",
    "        # Before the backward pass, zero all of the network gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass: compute gradient of the loss with respect to parameters\n",
    "        loss.backward()\n",
    "        # Perform gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        # Calling the step function to update the parameters\n",
    "        optimizer.step()\n",
    "        # Update the exponential moving average\n",
    "        #ema.update(model)\n",
    "        losses.append(loss)\n",
    "    model_output = []\n",
    "    # Print loss\n",
    "    if (t % 20 == 0):\n",
    "        print(loss)\n",
    "        model_output.append(model(torch.randn(dataset.shape), torch.tensor(t)))\n",
    "        x_seq = p_sample_loop(model, dataset.shape)\n",
    "        print('{}_th iter pass'.format(t))\n",
    "        fig, axs = plt.subplots(1, 10, figsize=(28, 3))\n",
    "        for i in range(1, 11):\n",
    "            cur_x = x_seq[i * 20].detach()\n",
    "            axs[i-1].scatter(cur_x[:, 0], cur_x[:, 1], s=10);\n",
    "            axs[i-1].set_title('$q(\\mathbf{x}_{'+str(i*20)+'})$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cebd01",
   "metadata": {},
   "source": [
    "Some other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DDIM(model_output,timesteps,num_trainstep,num_inferencestep,prediction_type = \"epsilon\", eta = 0.0):\n",
    "    t = timesteps\n",
    "    prev_t = t - self.config.num_train_timesteps // self.num_inference_steps\n",
    "    alpha_prod_t = self.alphas_cumprod[t]\n",
    "    alpha_prod_t_prev = self.alphas_cumprod[ torch.clip(prev_t, min=0) ]\n",
    "    alpha_prod_t_prev[ prev_t < 0 ] = torch.tensor(1.0)\n",
    "\n",
    "    beta_prod_t = 1 - alpha_prod_t\n",
    "    beta_prod_t_prev = 1 - alpha_prod_t_prev\n",
    "    \n",
    "    if prediction_type == \"epsilon\":\n",
    "        pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)\n",
    "        pred_epsilon = model_output\n",
    "    elif prediction_type == \"sample\":\n",
    "        pred_original_sample = model_output\n",
    "        pred_epsilon = (sample - alpha_prod_t ** (0.5) * pred_original_sample) / beta_prod_t ** (0.5)\n",
    "    elif prediction_type == \"v_prediction\":\n",
    "        pred_original_sample = (alpha_prod_t**0.5) * sample - (beta_prod_t**0.5) * model_output\n",
    "        pred_epsilon = (alpha_prod_t**0.5) * model_output + (beta_prod_t**0.5) * sample\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"prediction_type given as {self.config.prediction_type} must be one of `epsilon`, `sample`, or\"\n",
    "            \" `v_prediction`\"\n",
    "            )\n",
    "    \n",
    "    \n",
    "    variance = (beta_prod_t_prev / beta_prod_t) * (1 - alpha_prod_t / alpha_prod_t_prev)\n",
    "    std_dev_t = eta * variance ** (0.5)\n",
    "    #compute \"direction pointing to x_t\" of formula (12) from https://arxiv.org/pdf/2010.02502.pdf\n",
    "    pred_sample_direction = (1 - alpha_prod_t_prev - std_dev_t**2) ** (0.5) * pred_epsilon\n",
    "    #compute x_t without \"random noise\" of formula (12) from https://arxiv.org/pdf/2010.02502.pdf\n",
    "    prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction\n",
    "    \n",
    "    \n",
    "    return prev_sample, pred_sample_direction, std_dev_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bab65",
   "metadata": {},
   "source": [
    "EDM_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440a707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def edm_sampler( self, x, E, sample_algo = 'euler', randn_like=torch.randn_like, num_steps=400, sigma_min=0.002, sigma_max=10, rho=7,\n",
    "    S_churn=0, S_min=0, S_max=float('inf'), S_noise=1,):\n",
    "    # Adjust noise levels based on what's supported by the network.\n",
    "\n",
    "    #sigma_min = max(sigma_min, net.sigma_min)\n",
    "    #sigma_max = min(sigma_max, net.sigma_max)\n",
    "\n",
    "    gen_size = x.shape[0]\n",
    "\n",
    "    # Time step discretization.\n",
    "    step_indices = torch.arange(num_steps, dtype=torch.float32, device=x.device)\n",
    "    t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho\n",
    "    t_steps = torch.cat([torch.as_tensor(t_steps), torch.zeros_like(t_steps[:1])]) # t_N = 0\n",
    "\n",
    "    # Main sampling loop.\n",
    "    x_next = x.to(torch.float32) * t_steps[0]\n",
    "    for i, (t_cur, t_next) in enumerate(zip(t_steps[:-1], t_steps[1:])): # 0, ..., N-1\n",
    "        x_cur = x_next\n",
    "\n",
    "        # Increase noise temporarily.\n",
    "        gamma = min(S_churn / num_steps, np.sqrt(2) - 1) if S_min <= t_cur <= S_max else 0\n",
    "        t_hat = torch.as_tensor(t_cur + gamma * t_cur)\n",
    "        x_hat = x_cur + (t_hat ** 2 - t_cur ** 2).sqrt() * S_noise * randn_like(x_cur)\n",
    "\n",
    "        # Euler step.\n",
    "\n",
    "        t_hat_full = torch.full((gen_size,), t_hat, device=x.device)\n",
    "        denoised = self.denoise(x_hat, E, t_hat_full).to(torch.float32)\n",
    "        d_cur = (x_hat - denoised) / t_hat\n",
    "        x_next = x_hat + (t_next - t_hat) * d_cur\n",
    "\n",
    "\n",
    "\n",
    "        # Apply 2nd order correction.\n",
    "        if (sample_algo == 'edm') and (i < num_steps - 1):\n",
    "            t_next_full = torch.full((gen_size,), t_next, device=x.device)\n",
    "            denoised = self.denoise(x_next, E, t_next_full).to(torch.float32)\n",
    "            d_prime = (x_next - denoised) / t_next\n",
    "            x_next = x_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "    return x_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ad147",
   "metadata": {},
   "source": [
    "dpm-solver, need some special data form? Or is it properly used to density estimation task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpm-solver\n",
    "class NoiseScheduleVP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        schedule=\"discrete\",\n",
    "        betas=None,\n",
    "        alphas_cumprod=None,\n",
    "        continuous_beta_0=0.1,\n",
    "        continuous_beta_1=20.0,\n",
    "        dtype=torch.float32,\n",
    "    ):\n",
    "\n",
    "        if schedule not in [\"discrete\", \"linear\"]:\n",
    "            raise ValueError(\n",
    "                \"Unsupported noise schedule {}. The schedule needs to be 'discrete' or 'linear'\".format(schedule)\n",
    "            )\n",
    "\n",
    "        self.schedule = schedule\n",
    "        if schedule == \"discrete\":\n",
    "            if betas is not None:\n",
    "                log_alphas = 0.5 * torch.log(1 - betas).cumsum(dim=0)\n",
    "            else:\n",
    "                assert alphas_cumprod is not None\n",
    "                log_alphas = 0.5 * torch.log(alphas_cumprod)\n",
    "            self.T = 1.0\n",
    "            self.log_alpha_array = self.numerical_clip_alpha(log_alphas).reshape((1, -1)).to(dtype=dtype)\n",
    "            self.total_N = self.log_alpha_array.shape[1]\n",
    "            self.t_array = torch.linspace(0.0, 1.0, self.total_N + 1)[1:].reshape((1, -1)).to(dtype=dtype)\n",
    "        else:\n",
    "            self.T = 1.0\n",
    "            self.total_N = 1000\n",
    "            self.beta_0 = continuous_beta_0\n",
    "            self.beta_1 = continuous_beta_1\n",
    "    \n",
    "    def numerical_clip_alpha(log_alphas, clipped_lambda=-5.1):\n",
    "        \"\"\"\n",
    "        For some beta schedules such as cosine schedule, the log-SNR has numerical isssues. \n",
    "        We clip the log-SNR near t=T within -5.1 to ensure the stability.\n",
    "        Such a trick is very useful for diffusion models with the cosine schedule, such as i-DDPM, guided-diffusion and GLIDE.\n",
    "        \"\"\"\n",
    "        log_sigmas = 0.5 * torch.log(1. - torch.exp(2. * log_alphas))\n",
    "        lambs = log_alphas - log_sigmas  \n",
    "        idx = torch.searchsorted(torch.flip(lambs, [0]), clipped_lambda)\n",
    "        if idx > 0:\n",
    "            log_alphas = log_alphas[:-idx]\n",
    "        return log_alphas\n",
    "\n",
    "    def marginal_log_mean_coeff(self, t):\n",
    "        \"\"\"\n",
    "        Compute log(alpha_t) of a given continuous-time label t in [0, T].\n",
    "        \"\"\"\n",
    "        if self.schedule == \"discrete\":\n",
    "            return interpolate_fn(\n",
    "                t.reshape((-1, 1)), self.t_array.to(t.device), self.log_alpha_array.to(t.device)\n",
    "            ).reshape((-1))\n",
    "        elif self.schedule == \"linear\":\n",
    "            return -0.25 * t**2 * (self.beta_1 - self.beta_0) - 0.5 * t * self.beta_0\n",
    "\n",
    "    def marginal_alpha(self, t):\n",
    "        \"\"\"\n",
    "        Compute alpha_t of a given continuous-time label t in [0, T].\n",
    "        \"\"\"\n",
    "        return torch.exp(self.marginal_log_mean_coeff(t))\n",
    "\n",
    "    def marginal_std(self, t):\n",
    "        \"\"\"\n",
    "        Compute sigma_t of a given continuous-time label t in [0, T].\n",
    "        \"\"\"\n",
    "        return torch.sqrt(1.0 - torch.exp(2.0 * self.marginal_log_mean_coeff(t)))\n",
    "\n",
    "    def marginal_lambda(self, t):\n",
    "        \"\"\"\n",
    "        Compute lambda_t = log(alpha_t) - log(sigma_t) of a given continuous-time label t in [0, T].\n",
    "        \"\"\"\n",
    "        log_mean_coeff = self.marginal_log_mean_coeff(t)\n",
    "        log_std = 0.5 * torch.log(1.0 - torch.exp(2.0 * log_mean_coeff))\n",
    "        return log_mean_coeff - log_std\n",
    "\n",
    "    def inverse_lambda(self, lamb):\n",
    "        \"\"\"\n",
    "        Compute the continuous-time label t in [0, T] of a given half-logSNR lambda_t.\n",
    "        \"\"\"\n",
    "        if self.schedule == \"linear\":\n",
    "            tmp = 2.0 * (self.beta_1 - self.beta_0) * torch.logaddexp(-2.0 * lamb, torch.zeros((1,)).to(lamb))\n",
    "            Delta = self.beta_0**2 + tmp\n",
    "            return tmp / (torch.sqrt(Delta) + self.beta_0) / (self.beta_1 - self.beta_0)\n",
    "        elif self.schedule == \"discrete\":\n",
    "            log_alpha = -0.5 * torch.logaddexp(torch.zeros((1,)).to(lamb.device), -2.0 * lamb)\n",
    "            t = interpolate_fn(\n",
    "                log_alpha.reshape((-1, 1)),\n",
    "                torch.flip(self.log_alpha_array.to(lamb.device), [1]),\n",
    "                torch.flip(self.t_array.to(lamb.device), [1]),\n",
    "            )\n",
    "            return t.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.schedulers.scheduling_dpmsolver_multistep import DPMSolverMultistepScheduler\n",
    "from diffusers.schedulers.scheduling_utils import SchedulerOutput\n",
    "\n",
    "class ParaDPMSolverMultistepScheduler(DPMSolverMultistepScheduler):\n",
    "    self.lambda_t = self.lambda_t.to(model_output.device)\n",
    "    self.alpha_t = self.alpha_t.to(model_output.device)\n",
    "    self.sigma_t = self.sigma_t.to(model_output.device)\n",
    "\n",
    "    t = timesteps\n",
    "    matches = (self.timesteps[None, :] == t[:, None])\n",
    "    edgecases = ~matches.any(dim=1)\n",
    "    step_index = torch.argmax(matches.int(), dim=1)\n",
    "    step_index[edgecases] = len(self.timesteps) - 1 # if no match, then set to len(self.timesteps) - 1\n",
    "    edgecases = (step_index == len(self.timesteps) - 1)\n",
    "\n",
    "    prev_t = self.timesteps[ torch.clip(step_index+1, max=len(self.timesteps) - 1) ]\n",
    "    prev_t[edgecases] = 0\n",
    "\n",
    "    t = t.view(-1, *([1]*(model_output.ndim - 1)))\n",
    "    prev_t = prev_t.view(-1, *([1]*(model_output.ndim - 1)))\n",
    "\n",
    "    model_output = self.convert_model_output(model_output, t, sample)\n",
    "    model_output = model_output.clamp(-1, 1) # important\n",
    "\n",
    "\n",
    "    if self.config.solver_order == 1 or len(t) == 1:\n",
    "        prev_sample = self.dpm_solver_first_order_update(model_output, t, prev_t, sample)\n",
    "    elif self.config.solver_order == 2 or len(t) == 2:\n",
    "        # first element in batch must do first_order_update\n",
    "        prev_sample1 = self.dpm_solver_first_order_update(model_output[:1], t[:1], prev_t[:1], sample[:1])\n",
    "\n",
    "        model_outputs_list = [model_output[:-1], model_output[1:]]\n",
    "        timestep_list = [t[:-1], t[1:]]\n",
    "        prev_sample2 = self.multistep_dpm_solver_second_order_update(\n",
    "            model_outputs_list, timestep_list, prev_t[1:], sample[1:]\n",
    "        )\n",
    "\n",
    "        prev_sample = torch.cat([prev_sample1, prev_sample2], dim=0)\n",
    "    else:\n",
    "        # first element in batch must do first_order_update\n",
    "        prev_sample1 = self.dpm_solver_first_order_update(model_output[:1], t[:1], prev_t[:1], sample[:1])\n",
    "\n",
    "        # second element in batch must do second_order update\n",
    "        model_outputs_list = [model_output[:1], model_output[1:2]]\n",
    "        timestep_list = [t[:1], t[1:2]]\n",
    "        prev_sample2 = self.multistep_dpm_solver_second_order_update(\n",
    "            model_outputs_list, timestep_list, prev_t[1:2], sample[1:2]\n",
    "        )\n",
    "\n",
    "        model_outputs_list = [model_output[:-2], model_output[1:-1], model_output[2:]]\n",
    "        timestep_list = [t[:-2], t[1:-1], t[2:]]\n",
    "        prev_sample3 = self.multistep_dpm_solver_third_order_update(\n",
    "            model_outputs_list, timestep_list, prev_t[2:], sample[2:]\n",
    "        )\n",
    "\n",
    "        prev_sample = torch.cat([prev_sample1, prev_sample2, prev_sample3], dim=0)\n",
    "\n",
    "    # doing this otherwise set_timesteps throws an error\n",
    "    # if worried about efficiency, can override the set_timesteps function\n",
    "    self.lambda_t = self.lambda_t.to('cpu')\n",
    "\n",
    "    return prev_sample"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
